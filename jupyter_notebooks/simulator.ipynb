{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main notebook for the simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Right now focusing on linear road, using only an excerpt of tuples, and considering only position reports (tuples with type=0). The file has been created with\n",
    "  - `head -n 100000 input.txt | grep -e \"^0,\" > ../../../aggregate_modeling/data/input_stream_lr.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python related commands:\n",
    " - `conda create --name aggregate_modeling python=3.12 -y`\n",
    " - `conda activate aggregate_modeling`\n",
    " - `install ipykernel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/input_stream_lr.csv' \n",
    "mst_input_stream_file = '../data/MST_input_stream_lr.csv'\n",
    "mst_output_stream_file = '../data/MST_output_stream_lr.csv'\n",
    "mee_events_file = '../data/MEE_events_lr.csv'\n",
    "input_event_mapping =  '../data/input_event_lr.csv'\n",
    "event_output_mapping =  '../data/event_output_lr.csv'\n",
    "WA = 200 * 1000\n",
    "WS = 600 * 1000\n",
    "\n",
    "# Set to true if you also want to write input/event and event/output mappings. Mostly for debugging\n",
    "write_mappings = False\n",
    "\n",
    "extract_time = lambda line: int(line.split(\",\")[1])*1000  # Extracts second value as integer time, that's the format for LR tuples, multiplies by 1000 to get ms\n",
    "extract_key = lambda line: line.split(\",\")[2].strip()  # Extracts third value as key, the vehicle id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "CREATE_duration = lambda: random.uniform(0.001, 0.1)\n",
    "UPDATE_duration = lambda: random.uniform(0.001, 0.1)\n",
    "OUTPUT_duration = lambda: random.uniform(0.001, 0.1)\n",
    "DELETE_duration = lambda: random.uniform(0.001, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following are the main classes / utily functions / simulator code. Should not be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import csv\n",
    "from enum import Enum\n",
    "import sys\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Stream Tuple\n",
    "class MST:\n",
    "    def __init__(self, id, omega, tau, w, k):\n",
    "        self.id = id # The unique ID\n",
    "        self.omega = omega # The wallclock time\n",
    "        self.tau = tau # The event time\n",
    "        self.w = w # Boolean specifying whether this is a watermark or a regular tuple\n",
    "        self.k = k # The associated key\n",
    "\n",
    "    def to_list(self):\n",
    "        \"\"\"Convert the object to a list for CSV writing.\"\"\"\n",
    "        return [self.id, self.omega, self.tau, self.w, self.k]\n",
    "\n",
    "# Window Action\n",
    "class WinAction (Enum):  \n",
    "    CREATE = 1\n",
    "    UPDATE = 2\n",
    "    OUTPUT = 3\n",
    "    DELETE = 4\n",
    "\n",
    "# Model Execution Event\n",
    "class MEE:\n",
    "    def __init__(self, id, omega, tau, winAction, k):\n",
    "        self.id = id # The unique ID\n",
    "        self.omega = omega # The wallclock time\n",
    "        self.tau = tau # The event time\n",
    "        self.winAction = winAction # Action \n",
    "        self.k = k # The associated key\n",
    "\n",
    "    def to_list(self):\n",
    "        \"\"\"Convert the object to a list for CSV writing.\"\"\"\n",
    "        return [self.id, self.omega, self.tau, self.winAction, self.k]\n",
    "    \n",
    "def get_sliding_window_starts(tau, WA, WS):\n",
    "    \"\"\"\n",
    "    Returns a list of all starting times of sliding windows that contain tau.\n",
    "    \n",
    "    :param tau: The event time\n",
    "    :param WA: The window advance (step size)\n",
    "    :param WS: The window size\n",
    "    :return: A list of start times of windows containing tau\n",
    "    \"\"\"\n",
    "    start_times = []\n",
    "    latest_start = tau  # Latest possible window start containing tau\n",
    "    \n",
    "    while latest_start >= tau - WS + 1:\n",
    "        if latest_start % WA == 0:\n",
    "            start_times.append(latest_start)\n",
    "        latest_start -= 1\n",
    "    \n",
    "    return sorted(start_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stream(input_file, mst_input_stream, extract_time, extract_key):\n",
    "    counter = 0\n",
    "    last_tau = None\n",
    "    non_decreasing = True\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(mst_input_stream, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"id\", \"omega\", \"tau\", \"w\", \"k\"])  # CSV header\n",
    "\n",
    "        for line in infile:\n",
    "            tau = extract_time(line)  # Extract event time\n",
    "            k = extract_key(line)  # Extract key\n",
    "\n",
    "            # Check if tau decreased\n",
    "            if last_tau is not None and tau < last_tau:\n",
    "                non_decreasing = False\n",
    "\n",
    "            # If tau increased, insert a watermark tuple before the new tau\n",
    "            if last_tau is not None and tau > last_tau:\n",
    "                watermark = MST(counter, last_tau, last_tau, True, None)\n",
    "                writer.writerow(watermark.to_list())\n",
    "                counter += 1\n",
    "\n",
    "            # Create regular tuple\n",
    "            mst = MST(counter, tau, tau, False, k)\n",
    "            writer.writerow(mst.to_list())\n",
    "            counter += 1\n",
    "\n",
    "            last_tau = tau\n",
    "\n",
    "        # At the end, a final watermark that flushes everything\n",
    "        watermark = MST(counter, last_tau, sys.maxsize, True, None)\n",
    "        writer.writerow(watermark.to_list())\n",
    "        \n",
    "    return non_decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples had non-decreasing event times, so mst_input_stream_lr.csv can be used as is\n"
     ]
    }
   ],
   "source": [
    "non_decreasing = process_stream(input_file, mst_input_stream_file, extract_time, extract_key)\n",
    "\n",
    "if non_decreasing:\n",
    "    print('Tuples had non-decreasing event times, so mst_input_stream_lr.csv can be used as is')\n",
    "else:\n",
    "    print('Tuples had decreasing event times, so mst_input_stream_lr.csv should be adjusted to have consistent watermarks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  10%|â–‰         | 9705/100513 [03:42<34:45, 43.54row/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     91\u001b[39m                     output_counter += \u001b[32m1\u001b[39m\n\u001b[32m     93\u001b[39m                     accumulated_execution_time += DELETE_duration()\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[43mprocess_mst_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmst_input_stream_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmee_events_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_event_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmst_output_stream_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_output_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mprocess_mst_stream\u001b[39m\u001b[34m(mst_input_stream_file, mee_events_file, input_event_mapping, mst_output_stream_file, event_output_mapping, WA, WS)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m w:  \u001b[38;5;66;03m# Regular tuple\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Adjust the accumulated time\u001b[39;00m\n\u001b[32m     47\u001b[39m     accumulated_execution_time = \u001b[38;5;28mmax\u001b[39m(omega, accumulated_execution_time)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m start_time \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_sliding_window_starts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWS\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (start_time, k) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m wins:\n\u001b[32m     51\u001b[39m             \u001b[38;5;66;03m# A window is being created\u001b[39;00m\n\u001b[32m     52\u001b[39m             wins.add((start_time, k))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mget_sliding_window_starts\u001b[39m\u001b[34m(tau, WA, WS)\u001b[39m\n\u001b[32m     43\u001b[39m start_times = []\n\u001b[32m     44\u001b[39m latest_start = tau  \u001b[38;5;66;03m# Latest possible window start containing tau\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m latest_start >= tau - WS + \u001b[32m1\u001b[39m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m latest_start % WA == \u001b[32m0\u001b[39m:\n\u001b[32m     48\u001b[39m         start_times.append(latest_start)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def process_mst_stream(\n",
    "    mst_input_stream_file,  # Input CSV for MST input tuples\n",
    "    mee_events_file,  # Output CSV for MEE events\n",
    "    input_event_mapping,  # Output CSV for input-event mappings\n",
    "    mst_output_stream_file, # Input CSV for MST output tuples\n",
    "    event_output_mapping, # Output CSV for event-output mappings\n",
    "    WA,  # Window advance (step size)\n",
    "    WS  # Window size\n",
    "):\n",
    "    \n",
    "    wins = set() # Set keeping track of the open windows\n",
    "    pendingMEEs = [] # Buffer of temporary events that are waiting for a watermark to be triggered\n",
    "    event_counter = 0 # counter used as id of the MEE events\n",
    "    output_counter = 0 # counter used as id of MST output tuples\n",
    "    accumulated_execution_time = 0.0 # used to keep track of actual execution time of each window action/output tuple\n",
    "    \n",
    "    with open(mst_input_stream_file, 'r') as infile, \\\n",
    "            open(mee_events_file, 'w', newline='') as out_mee, \\\n",
    "            open(input_event_mapping, 'w', newline='') as out_event_map, \\\n",
    "            open(mst_output_stream_file, 'w', newline='') as output, \\\n",
    "            open(event_output_mapping, 'w', newline='') as event_output:\n",
    "        \n",
    "        mst_reader = csv.reader(infile)\n",
    "        next(mst_reader)  # Skip header\n",
    "\n",
    "        # This part is to show a progress bar\n",
    "        total_rows = sum(1 for _ in infile)  # Count total rows\n",
    "        infile.seek(0)  # Reset file pointer\n",
    "        next(mst_reader)  # Skip header again\n",
    "        \n",
    "        mee_writer = csv.writer(out_mee)\n",
    "        event_map_writer = csv.writer(out_event_map)\n",
    "        output_writer = csv.writer(output)\n",
    "        event_output_writer = csv.writer(event_output)\n",
    "        \n",
    "        mee_writer.writerow([\"i\", \"omega\", \"tau\", \"winAction\", \"k\"])\n",
    "        event_map_writer.writerow([\"input_id\", \"event_id\"])\n",
    "        output_writer.writerow([\"i\", \"omega\", \"tau\", \"w\", \"k\", \"l\"])\n",
    "        event_output_writer.writerow([\"event_id\", \"output_id\"])\n",
    "        \n",
    "        for row in tqdm(mst_reader, total=total_rows, desc=\"Processing Rows\", unit=\"row\"):\n",
    "            i, omega, tau, w, k = int(row[0]), int(row[1]), int(row[2]), row[3] == 'True', row[4] if row[4] != 'None' else None\n",
    "        \n",
    "            if not w:  # Regular tuple\n",
    "\n",
    "                # Adjust the accumulated time\n",
    "                accumulated_execution_time = max(omega, accumulated_execution_time)\n",
    "\n",
    "                for start_time in get_sliding_window_starts(tau, WA, WS):\n",
    "                    if (start_time, k) not in wins:\n",
    "                        # A window is being created\n",
    "                        wins.add((start_time, k))\n",
    "                        # output the event\n",
    "                        mee_writer.writerow([event_counter, int(accumulated_execution_time), start_time, WinAction.CREATE.name, k])\n",
    "                        if write_mappings:\n",
    "                            event_map_writer.writerow([i, event_counter])\n",
    "                        # Keep track of time passing\n",
    "                        accumulated_execution_time += CREATE_duration()\n",
    "                        # Remember there's an output (and a delete action to take care of later on)\n",
    "                        bisect.insort(pendingMEEs, [None, None, start_time + WS - 1, WinAction.OUTPUT.name, k], key=lambda x: x[2])\n",
    "                        event_counter += 1\n",
    "                    \n",
    "                    mee_writer.writerow([event_counter, int(accumulated_execution_time), start_time, WinAction.UPDATE.name, k])\n",
    "                    if write_mappings:\n",
    "                        event_map_writer.writerow([i, event_counter])\n",
    "                    event_counter += 1\n",
    "            else:  # Watermark\n",
    "                while pendingMEEs and pendingMEEs[0][2] <= tau:\n",
    "                    \n",
    "                    # pop the output event and adjust times\n",
    "                    x = pendingMEEs.pop(0)\n",
    "                    x[0] = event_counter\n",
    "                    x[1] = int(accumulated_execution_time)\n",
    "                    output_event_time = x[2]\n",
    "                    k = x[4]\n",
    "                    \n",
    "                    # Write the output event\n",
    "                    mee_writer.writerow(x)\n",
    "                    if write_mappings:\n",
    "                        event_map_writer.writerow([i, event_counter])\n",
    "                    \n",
    "                    # Adjust accumulated time\n",
    "                    accumulated_execution_time += OUTPUT_duration()\n",
    "\n",
    "                    # Write output\n",
    "                    output_writer.writerow([output_counter, int(accumulated_execution_time), output_event_time, False, k, int(accumulated_execution_time)-omega])\n",
    "                    if write_mappings:\n",
    "                        event_output_writer.writerow([event_counter, output_counter])\n",
    "                    \n",
    "                    # Now write the deletion event\n",
    "                    mee_writer.writerow([event_counter+1, int(accumulated_execution_time), None, WinAction.DELETE.name, x[4]])\n",
    "                    if write_mappings:\n",
    "                        event_map_writer.writerow([i, event_counter+1])\n",
    "                    \n",
    "                    event_counter += 2\n",
    "                    output_counter += 1\n",
    "\n",
    "                    accumulated_execution_time += DELETE_duration()\n",
    "                    \n",
    "\n",
    "process_mst_stream(mst_input_stream_file, mee_events_file, input_event_mapping, mst_output_stream_file, event_output_mapping, WA, WS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on the experiments \n",
    "\n",
    "## 25/03/10\n",
    "- Seems correct, but also extremely slow. Around 45 rows/second (or tuples/second)\n",
    "- Of course one of the fundamental things is to show that the simulator is significantly faster then the actual aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggregate_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
