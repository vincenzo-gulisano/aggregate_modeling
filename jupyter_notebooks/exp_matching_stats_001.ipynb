{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880d2017",
   "metadata": {},
   "source": [
    "let's call this experiment the matching_stats_001\n",
    "\n",
    "The idea is to have statistics collected from the real aggregate and from the simulation, and the two match.\n",
    "\n",
    "As of now, I have statistics collected fomr the simulation and some statistics from the real one, but they are not the same, so step one is to make a decision on the stats\n",
    "\n",
    "Other things for sure:\n",
    "- We need more data, and for sure we need a data generator\n",
    "- We should have an injector (in the real aggregate, that waits before sending each tuple according to the time that needs to pass)\n",
    "- In the real aggregate, I should probably add some artificial load that resembles that used in the simulation of course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e58fea",
   "metadata": {},
   "source": [
    "### 2025/04/13\n",
    "\n",
    "- Trying to add CPU stats to the PyFlink implementation (co-pilot)\n",
    "- Now we write CPU for all threads, and we have threads ids, so there needs to be post-completion cleaning of the folder\n",
    "\n",
    "#Questions/observations:\n",
    "- do we want to monitor the CPU of the aggregate or the entire Aggregate query or can be any of the 2?\n",
    "- we could also discuss two approaches, one in which you run the aggregate a couple of times to learn it's stats, the other in which you just try a model with many different stats/durations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe2ead",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
